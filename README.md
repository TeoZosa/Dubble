# Dubble
##### The Prehab Partner
<div align="center">

<img src="https://user-images.githubusercontent.com/13070236/31516102-2ce331d4-af4c-11e7-9c08-8488ec3969ea.png" title="Introduction Screens"></img>


<img src="https://user-images.githubusercontent.com/13070236/31516951-22ecbd8c-af4f-11e7-83c6-9d0850fcaff4.jpg" title="Algorithm Usefulness: Learning Preferences Across Tasks Simultaneously" style="width:150px;height:150px;"></img>

</div>
<img src="https://user-images.githubusercontent.com/13070236/31516012-0b4d4af0-af4c-11e7-927f-cec72d56df26.gif" title="Example Usage" style="width:302px;height:348px;"></img>

-----------------

## Swift 4

This code is written in Swift 4 ( Obj-C bridging header used for Double SDK compatability). 

## Highlights

- `Dubble` is a personified, adaptive agent that guides users through "prehabilitation" exercises, 
adjusting its display height to their facial height and performing miscellaneous physical gestures to increase user engagement.  

- Originally designed for use in an experiment to validate novel preference learning algorithms (see above storyboard for why these algorithms are so cool) developed by Bryce Woodworth, M.S. 

- Currently in the "research code" phase; needs to be refactored to do things efficiently/conform to best programming practices.

## Forthcoming
- Greater autonomous interaction 
- Wider range of applications


# Acknowledgements

Many thanks to Michelle Yu, PT, for her assistance in the development of the prehabilitation routine, 
and Monique F. Narboneta for designing the study robot's interface layout as well as the algorithm overview figures.
